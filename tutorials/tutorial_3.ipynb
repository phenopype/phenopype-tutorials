{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: The phenopype workflow\n",
    "\n",
    "Analysis of scientific images can be an iterative process that may require users to go back and forth, trying different processing steps and check how to improve results. Later, when the best functions and appropriate settings are found and efficient data collection has priority, image analysis should be efficient and with minimal user input to increase throughput and reproducibility. In phenopype, users can choose between two different workflows that are useful for different stages in the process of scientific image analysis:\n",
    "\n",
    "| Workflow | Use case | Operation principle | Code explicitness | Data reproducibility |\n",
    "|:---|:---------|:------------|:---|:---|\n",
    "| **Low throughput** | \"prototyping\" - self education and evaluation on single images and small datasets | image analysis functions are written and stored in Python | high | low |\n",
    "| **High throughput**  | \"production\" - default workflow for larger image datasets | images analysis functions are written and stored in YAML format | low | high |\n",
    "\n",
    "In the **low throughput** workflow, users write a function stack in directly in Python code. This is recommended for users who wish to familiarize themselves with the basic principles of computer vision or when working with only a handful of images. In contrast, the **high throughput** workflow is for production stage, when image analysis should be efficient and data collection reproducible for other users and scientists. In this tutorial you will learn about the differences between the two workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Further resources related to the high throughput workflow**\n",
    "\n",
    "*   [Window control covered in Tutorial 2](tutorial_2_phenopype_images.ipynb#Window-control)\n",
    "*   [pype section in the API](https://mluerig.github.io/phenopype/api.html#pype-high-throughput-function)\n",
    "*   [YAML indentation and separation](https://www.tutorialspoint.com/yaml/yaml_indentation_and_separation.htm).\n",
    "*   [the structure of digital images](https://mluerig.github.io/phenopype/resources.html#computer-vision)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example task\n",
    "    \n",
    "Here the goal is to measure lateral armor plating in threespine stickleback (*Gasterosteus aculeatus*). First we need to draw a mask around posterior region that contains the plates. For that step you should select the boundaries around the area of interest, perform a thresholding operation inside the mask, and retrieve the contours inside. The procedure to extract bone-plate area is the same in all workflows, but workflows differ in the amount of explicit Python code, and in reproducibility. \n",
    "\n",
    "<center>\n",
    "<br>\n",
    "<div style=\"text-align: left\" >\n",
    "<img  src=\"_assets/images/luerig_2021_figure2.jpg\">\n",
    "    \n",
    "**Fig. 1:** Workflow demonstration using a stained stickleback (*Gasterosteus aculeatus*) stained with alizarin red. Traits to be extracted area and shape of bone-plates, and, within the detected plates, pixel intensities that denote bone-density. Shown are visual feedback (A) from low-throughput (B) and high-throughput workflow (C), which use the same computer functions, but differ in the way these functions are called by the user: while in the low-throughput workflow all functions have to be explicitly coded in Python, the high-throughput routine parses the functions from human readable YAML files to facilitate rapid user interaction and increase reproducibility (Figure 2 from [LÃ¼rig 2021](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13771)).\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low throughput workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the low throughput workflow, the output of every function needs to be explicitly passed on to the next step. First we need to use  `load_image`, which imports the file as a three-channel numpy array (*ndarray*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "filepath = r\"images/stickle1.jpg\"\n",
    "\n",
    "## load image as array, supply image_data (DataFrame containing meta data)\n",
    "image = pp.load_image(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run `create_mask` - use left mouse clicks to trace an outline around some of the fish plates, right mouse to remove erroneous points, and finish masking the region with `Enter`. Note that the connection between the last two points is drawn automatically, no need to click on the starting point. Then run all remaining code cells on by one, we will visualize the result at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<br>\n",
    "<div style=\"text-align: left; width:400px\" >\n",
    "<img src=\"_assets/images/masks2.gif\">\n",
    "    \n",
    "**Fig. 2** Draw a mask around the armour plates. Finish with `Enter`.\n",
    "\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw mask\n",
    "mask = pp.preprocessing.create_mask(image, tool=\"polygon\", window_max_dim=1200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After drawing a mask around the bone plates, we pass the mask on to the `threshold` function. Thresholding will convert a three dimensional array into a one dimensional binary array of the same width and hight (white denoting foreground, black denoting background). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- decompose image: using red channel\n",
      "- including pixels from 1 drawn masks \n"
     ]
    }
   ],
   "source": [
    "## thresholding converts multichannel to binary image\n",
    "image_bin = pp.segmentation.threshold(image, method=\"adaptive\", \n",
    "                                      channel=\"red\", blocksize=199, \n",
    "                                      constant=5, mask=mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- found 7 contours that match criteria\n"
     ]
    }
   ],
   "source": [
    "## detect contours ony binary image\n",
    "contours = pp.segmentation.detect_contour(image_bin, retrieval=\"ext\", min_area=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- creating new annotation file\n",
      "- writing annotation of type \"contour\" with id \"a\" to \"annotations.json\"\n"
     ]
    }
   ],
   "source": [
    "## export contours\n",
    "pp.export.save_annotation(contours, annotation_id = \"a\", dirpath = r\"_temp/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can visualize the contours found by `detect_contour`. Note that we first have to draw them explicitly on a \"canvas\", i.e. a background for visualization. We could draw them on the original image, but then it would be unusable for further work. It is better practice to make a copy using the `copy` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "## copy the image \n",
    "canvas = copy.deepcopy(image)\n",
    "\n",
    "## draw detected contours onto canvas\n",
    "image_drawn = pp.visualization.draw_contour(canvas, contours)  \n",
    "\n",
    "## show convas\n",
    "pp.show_image(image_drawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While analyzing the image, you can explore output from the different steps to see what is going on. For example, the binary image resulting from the thresholding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High throughput worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the default workflow to analyse medium and large image datasets in phenopype. Here, instead of writing down our analysis as a sequence of Python code, as we did in the low throughput workflow, we supply the same functions through a configuration file in human readable `YAML` format. This file can then be loaded by phenopype's `pype` class, which initiates the analysis by triggering three actions: \n",
    "\n",
    "1. open the YAML configuration file in the default OS text editor\n",
    "2. parse the contained functions and execute them in the sequence\n",
    "3. open a HighGUI window showing the processed image, updates with every step\n",
    "\n",
    "After one iteration of all steps, users can evaluate the results and decide to modify the opened configuration file (e.g. either change function parameters or add new functions), and run `pype` again, or to terminate the `pype`-run and save all results. The processed image, any extracted phenotypic information, as well as the modified config-file is stored inside a phenopype `container`, and inside a directory specified with `dirpath`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "    \n",
    "<center><img src=\"_assets/images/luerig_2021_figure_3C.jpg\" width=500></center>    \n",
    "    \n",
    "**Fig 2** The Pype class in a for loop will trigger a series of events for each image directory provided by the loop generator: i) open the contained yaml configuration with the default OS text editor, ii) parse and execute the contained functions from top to bottom, iii) open a GUI window and show the processed image. Once the Pype class has finished executing all functions from the configuration file, users can decide to either modify the opened configuration file (e.g. either change function parameters or add new functions), which will trigger to run the Pype class again, or to close the GUI window, which will terminate the Pype class instance and save all results to the folder (Figure 3C from [LÃ¼rig 2021](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13771)).\n",
    "    \n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**IMPORTANT - read before continuing:**\n",
    "    \n",
    "1. Window control is as covered in [Tutorial 2](tutorial_2.ipynb#Window-control)). Don't use the close button, make sure that the window is selected / highlighted when you use the key combinations to close or interact with it:  \n",
    "    \n",
    "- `Enter` - finish an interactive step / function in `pype`-mode (e.g. creating a mask)\n",
    "- `Ctrl+Enter` - close and finish a window in `pype`-mode \n",
    "- `Esc` - close a window and quit the Phenoype process that invoked it (e.g. a `for` loop - [see Tutorial 4](tutorial_4.ipynb#Using-pype-with-project-folders)). This may also work when the process is frozen. \n",
    "    \n",
    "2. At the current stage of development, phenopype cannot handle errors resulting from incorrect yaml syntax (e.g. missing spaces or wrong indentation). Consult the section [YAML-syntax (below)](#YAML-syntax) to learn how to correctly modify the configuration files.\n",
    "\n",
    "2. The `pype` attempts to facilate rapid processing by calling some functions automatically (e.g. to visualize and export the results). Consult the [pype section in the API](https://mluerig.github.io/phenopype/api.html#pype-high-throughput-function) to learn about the most important aspects of the `pype` function.\n",
    "    \n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to save phenopype-container output set to parent folder of image:\n",
      "D:\\workspace\\git-repos\\phenopype-tutorials\\images\n",
      "\n",
      "AUTOLOAD\n",
      " - nothing to autoload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pype' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8f9f7049fd21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdirpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"_temp/output\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m## directory where output is stored (folder needs to exist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"demo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# name of the  pype routine, appended to all results-files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtemplate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tut3\"\u001b[0m \u001b[1;31m# template for the analysis - you can create your own!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         )\n",
      "\u001b[1;32md:\\workspace\\git-repos\\phenopype\\phenopype\\main.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, image, name, config, template, dirpath, debug, skip, autosave, feedback, visualize, **kwargs)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;31m## check pype config for annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m         self._iterate(config=self.config, annotations=self.container.annotations,\n\u001b[0m\u001b[0;32m    991\u001b[0m                       execute=False, visualize=False, feedback=False)\n\u001b[0;32m    992\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pype' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "filepath = r\"images/stickle1.jpg\"\n",
    "\n",
    "pype_demo = pp.Pype(image=filepath, # input - can be also an array or a phenopype directory \n",
    "        dirpath = r\"_temp/output\", ## directory where output is stored (folder needs to exist)\n",
    "        name=\"demo\", # name of the  pype routine, appended to all results-files \n",
    "        template=\"tut3\" # template for the analysis - you can create your own!\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all results and intermediate data results are saved under `\"_temp/output\"`, but also contained in a container that is part of the `pype`-object which we called `pype_demo`. You can use it to access e.g. the binary images, as we did in the other workflows above, and visualize it manually: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(pype_demo.container.image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can modify the configuration files to change the outcome. For instance, try to change the `blocksize` argument in `threshold` to `49`, or `499`, and see what happens. If you do so while the window is open, phenopype will update the image window and show the updated results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration files needed to run the pype are written in yaml (a recursive acronym for \"YAML Ain't Markup Language\"). In principle, these are just text files that follows a specific set of rules for indentation and separation. Let's look at the configuration template for this tutorial that we used above - we can look at *all* templates using `pype_config_templates`, and inspect a specific template using `show_config_template`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "pp.pype_config_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_config_template(\"tut3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text inside the yaml configuration files is parsed by Python from top to bottom and converted back to Python code in the background, i.e. to phenopype modules and functions. Indentation hierarchy is as follows:\n",
    "\n",
    "1. The first level without any indentation, e.g. `-preprocessing` or `- segmentation`, denote from the module that a function is part of. \n",
    "2. The second level with two-space indentation before the hyphen, e.g. `- threshold` or `- find_contours` are functions that are loaded from the `segmentation` module. \n",
    "3. The third level without hyphens, e.g. `method: otsu` and `blocksize: 99`, are arguments passed on to the function. \n",
    "\n",
    "Following this notation, the yaml parser in Python interprets the first item in `segmentation` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pp.segmentation.threshold(image, method=\"adaptive\", blocksize=199, constant=5, channel=\"red\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the pype routine, `image` is automatically loaded and passed to all following functions. You can add or remove functions as you like. Note in the hyphenated first two levels you can  specify modules and functions as many times as you want  (`- ` is the yaml list notation). When adding or modifying modules and functions, it is important to keep in mind that the **function stack is executed sequentially**. So, if you want to perform a `morphology` operation on a binary images, it should come *after* and not before the main segmentation function (in this case `threshold`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Here are the most important rules for YAML syntax:**\n",
    "\n",
    "- **indentation rules:**  \n",
    "    - 0 spaces for modules\n",
    "    - 2 spaces + hyphen+space in front of functions \n",
    "    - 4 spaces in front of arguments\n",
    "- **separation rules:** \n",
    "    - modules and functions with arguments are followed by a colon (`:`) and a new line\n",
    "    - functions without specified arguments don't need a colon \n",
    "    - arguments are followed by a colon, a space and then the value\n",
    "- modules and functions can be emtpy (see`- draw_masks` above), but function arguments *cannot* be emtpy (e.g. `overwrite:` needs to be `true` or `false`)\n",
    "- as per Python syntax, optional function arguments can, but don't have to be specified and the functions will just run on default values\n",
    "- functions can be added multiple times, but sometimes their output may be overwtritten (e.g. `- threshold` makes sense only once, but `- blur` may be used in multiple locations)\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn how to analyze entire data sets with the high-throughput method, move on to the next [Tutorial 4](tutorial_4_managing_projects.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
